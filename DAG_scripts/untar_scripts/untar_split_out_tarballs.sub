# split_channels.sub
# script to submit job to split channels from staged & calibrated LGLBS measurement set
#
# Specify the HTCondor Universe (vanilla is the default and is used
#  for almost all jobs) and your desired name of the HTCondor log file,
#  which is where HTCondor will describe what steps it takes to run 
#  your job. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.
universe = vanilla
#
# Specify your executable (single binary or a script that runs several
#  commands), arguments, and a files for HTCondor to store standard
#  output (or "screen output").
#  $(Process) will be a integer number for each job, starting with "0"
#  and increasing for the relevant number of jobs.
executable = untar_split_out_tarballs.sh

## set up start and end channels
sc = $(Process)*20
ec = $(sc) + 20
start_chan = $INT(sc,%d)
end_chan = $INT(ec,%d)

arguments = $(start_chan) $(end_chan) 
output = untar_split_channels_$(start_chan)_to_$(end_chan).out
error = untar_split_channels_$(start_chan)_to_$(end_chan).err
log = untar_split_channels_$(start_chan)_to_$(end_chan).log
#
# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to use.
Requirements=(Target.HasCHTCStaging == true)
+HasCHTCStaging=true
# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
request_cpus = 4
request_memory = 10GB
request_disk = 300GB
#
# Tell HTCondor to run 1 instances of our job:
queue 200
